---
title: "T028 otolith/GT-seq match: First live test of 12 96-well transfer plates"
output:
  html_notebook:
    theme: united
    toc: yes
editor_options: 
  chunk_output_type: inline
---

```{r setup, message=FALSE, results='hide'}
rm(list=ls())

knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(DT)
library(abind)
bbind <- function(...) { abind(..., along = 3) }

.username <- "kmgruenthal"
.password <- ""

source("~/R/Functions.GCL.R")
source("LOKI2R_ind.GCL.R")
source("DupCheckBetweenSillys_all.GCL.r")
```

# Objective

The purpose of this notebook is to determine whether we can successfully re-pair GTseq genotypes from otolith-derived DNA with GT-seq genotypes from heart-derived DNA for individuals of unknown origin.

# Background

During shipment of otolith samples to the MTA in Juneau for reading, a significant proportion of otoliths migrated between cells within DWPs due to poor containment of the acetate lids that were attached with rubber bands to the DWPs. This incident is known as "the great otolith debacle", aka the "GOD" incident. Since some otoliths moved from their original cells in the DWP, the paired integrity of the otolith-origin information and the rest of the paired data (genotype + field data) was lost for many individuals. In an attempt to rectify the "GOD" incident, we are extracting DNA from the otolith tissues, genotyping the otolith-derived DNA at 298 GT-seq loci, and attempting to re-pair the otolith-heart samples from their genotypes.  

# Methods

DNA was extracted from left-side or unknown otolith tissues of unknown origin using conventional Machery-Nagel DNA extraction kits. Otoliths were placed in T1 buffer for an overnight soak in clear 96 shallow-well plates (SWP). Preamp at 14 cycles. Final elution volume was 75uL. All otoliths were transferred among plates with a jig. All liquid handling was done by robot. 

## LocusControl

```{r}
TestSillys <- "PGOD21"

loci <- dget("../../Objects/loci298.txt") # saved list of loci

CreateLocusControl.GCL(locusnames = loci, username = .username, password = .password)
loci <- LocusControl$locusnames
nalleles <- LocusControl$nalleles
ploidy <- LocusControl$ploidy
alleles <- LocusControl$alleles

# change sillyvec as needed
LOKI2R.GCL(sillyvec = TestSillys, username = .username, password = .password)
```

```{r}
# create a csv from the otolith transfer spreadsheet from MTAL, read in the data, and create a concatenated tray and well column
oto_xfer_data_042721 <- read_csv("otolith_transfer_042721.csv")
oto_xfer_data_042721$DNA_TRAY_AND_WELL <- paste0(oto_xfer_data_042721$`96_oto_tray_barcode`, "_", oto_xfer_data_042721$`96_oto_tray_position`)
  
# download csv of PGOD21 sample data from OceanAK and append with _PGOD21
oceanak_PGOD21 <- read_csv("GEN_SAMPLED_FISH_TISSUE_PGOD21.csv")

# pull the attributes table from PGOD21.gcl, create a new tray a well column, and join with the otolith transfer data
attributes_PGOD21 <- PGOD21.gcl$attributes %>%
  transform(DNA_TRAY_CODE = as.numeric(DNA_TRAY_CODE))
attributes_PGOD21$DNA_TRAY_AND_WELL <- paste0(attributes_PGOD21$DNA_TRAY_CODE, "_", attributes_PGOD21$DNA_TRAY_WELL_CODE)
attributes_and_xfer_PGOD21 <- left_join(attributes_PGOD21, oto_xfer_data_042721, by = "DNA_TRAY_AND_WELL")

# get a list of the affected DWPs
affected_DWPs <- unique(attributes_and_xfer_PGOD21$`48_DWP_tray_barcode`)

# filter OceanAK data pull for the list of affected DWPs
AHRP_oceanak_pull_092021 <- read_csv(file = "../../OceanAK/AHRP Salmon Biological Data 20210920_135754.csv") # do a new pull if latest date stamp is old
oceanak_affected_DWPs <- AHRP_oceanak_pull_092021[AHRP_oceanak_pull_092021$DNA_TRAY_CODE %in% affected_DWPs, ]
write_csv(oceanak_affected_DWPs, "oceanak_affected_DWPs.csv")

# get fish IDs for affected DWPs
DWP_sillys <- unique(oceanak_affected_DWPs$SILLY_CODE)

DWP_fish_ids <- oceanak_affected_DWPs %>% 
  dplyr::select(SILLY_CODE, FISH_ID) 

PERB15_fish_ids <- DWP_fish_ids %>% 
  dplyr::filter(SILLY_CODE == "PERB15") %>% 
  pull(FISH_ID)
PERB16_fish_ids <- DWP_fish_ids %>% 
  dplyr::filter(SILLY_CODE == "PERB16") %>% 
  pull(FISH_ID)
PERB17_fish_ids <- DWP_fish_ids %>% 
  dplyr::filter(SILLY_CODE == "PERB17") %>% 
  pull(FISH_ID)
PGILMOUR15_fish_ids <- DWP_fish_ids %>% 
  dplyr::filter(SILLY_CODE == "PGILMOUR15") %>% 
  pull(FISH_ID)
PGILMOUR16_fish_ids <- DWP_fish_ids %>% 
  dplyr::filter(SILLY_CODE == "PGILMOUR16") %>% 
 pull(FISH_ID)
PGILMOUR17_fish_ids <- DWP_fish_ids %>% 
  dplyr::filter(SILLY_CODE == "PGILMOUR17") %>% 
  pull(FISH_ID)
PGILMOUR18_fish_ids <- DWP_fish_ids %>% 
  dplyr::filter(SILLY_CODE == "PGILMOUR18") %>% 
  pull(FISH_ID)
PPADDY16_fish_ids <- DWP_fish_ids %>% 
  dplyr::filter(SILLY_CODE == "PPADDY16") %>% 
  pull(FISH_ID)

# Project SILLYs
# Note that some SILLYs are included in the affected DWPs whose hearts haven't been genotyped yet (e.g., PERB15 and PERB17)

# By otolith transfer plate ID
# Plate50917 <- c("PGILMOUR15", "PPADDY16")
# Plate50927 <- c("PGILMOUR15", "PGILMOUR16")
# Plate50936 <- c("PERB16")
# Plate50947 <- c("PGILMOUR17", "PGILMOUR18")
# Plate50956 <- c("PERB16")
# Plate50964 <- c("PGILMOUR17", "PGILMOUR18")
# Plate50974 <- c("PERB16", "PGILMOUR17", "PGILMOUR18")
# Plate50994 <- c("PERB16")
# Plate50995 <- c("PGILMOUR18", "PPADDY16")
# Plate50997 <- c("PGILMOUR16")
# Plate50999 <- c("PPADDY16", "PGILMOUR17", "PGILMOUR18")
# Plate51000 <- c("PGILMOUR15", "PGILMOUR17", "PGILMOUR18")

# By individuals in a SILLY per affected DWP
# PERB15 <- "PERB15"
# LOKI2R_ind.GCL(sillyvec = PERB15, fish_ids = PERB15_fish_ids, username = .username, password = .password)

PERB16 <- "PERB16"
LOKI2R_ind.GCL(sillyvec = PERB16, fish_ids = PERB16_fish_ids, username = .username, password = .password)

# PERB17 <- "PERB17"
# LOKI2R_ind.GCL(sillyvec = PERB17, fish_ids = PERB17_fish_ids, username = .username, password = .password)

PGILMOUR15 <- "PGILMOUR15"
LOKI2R_ind.GCL(sillyvec = PGILMOUR15, fish_ids = PGILMOUR15_fish_ids, username = .username, password = .password)

PGILMOUR16 <- "PGILMOUR16"
LOKI2R_ind.GCL(sillyvec = PGILMOUR16, fish_ids = PGILMOUR16_fish_ids, username = .username, password = .password)

PGILMOUR17 <- "PGILMOUR17"
LOKI2R_ind.GCL(sillyvec = PGILMOUR17, fish_ids = PGILMOUR17_fish_ids, username = .username, password = .password)

PGILMOUR18 <- "PGILMOUR18"
LOKI2R_ind.GCL(sillyvec = PGILMOUR18, fish_ids = PGILMOUR18_fish_ids, username = .username, password = .password)

PPADDY16 <- "PPADDY16"
LOKI2R_ind.GCL(sillyvec = PPADDY16, fish_ids = PPADDY16_fish_ids, username = .username, password = .password)

rm(.username, .password)
```

Create new directories and save objects

```{r save_locus_control_sillys}
if(!dir.exists("../../Objects/GOD_21_Round1/")) {dir.create("../../Objects/GOD_21_Round1/")}
save_objects(objects = c("LocusControl", "loci", "TestSillys", "PERB16", "PGILMOUR15", "PGILMOUR16", "PGILMOUR17", "PGILMOUR18", "PPADDY16"), path = "../../Objects/GOD_21_Round1/")

if(!dir.exists("../../Genotypes/GOD_21_Round1/")) {dir.create("../../Genotypes/GOD_21_Round1/")}
save_sillys(sillyvec = c("PGOD21", "PERB16", "PGILMOUR15", "PGILMOUR16", "PGILMOUR17", "PGILMOUR18", "PPADDY16"), path = "../../Genotypes/GOD_21_Round1/")
```

### Otolith genotyping success

```{r fig.height=12}
TestQCSampleSizebyLocus <-
  SampSizeByLocus.GCL(sillyvec = TestSillys, loci = loci)

TestQCPercentbyLocus <-
  apply(TestQCSampleSizebyLocus, 1, function(row) {
    row / max(row)
  })

(locus_success_rate_qc <- TestQCPercentbyLocus %>% 
  as_tibble(rownames = "locus") %>%
  dplyr::rename(success_rate = PGOD21) %>%
  arrange(success_rate))

locus_success_rate_qc %>%
  filter(success_rate == 0)

(failed_loci_otoliths <- locus_success_rate_qc %>%
  filter(success_rate == 0) %>%
  pull(locus))

# Added by Chase Jalbert on 4/2020. This version of a levelplot has WAY more features and actually works with large datasets.
# plotly::ggplotly(
#   ggplot(
#     TestQCPercentbyLocus %>%
#       as_tibble(rownames = "locus") %>%
#       gather(silly, percent,-locus),
#     aes(x = silly, y = locus)
#   ) +
#     geom_tile(aes(fill = percent), color = "white") +
#     scale_fill_gradient(
#       low = "black",
#       high = "white",
#       limits = c(0, 1)
#     ) +
#     ylab("Locus") +
#     xlab("SILLY") +
#     ggtitle("Percent PGOD21 genotyped by Locus") +
#     labs(fill = "Percent\ngenotyped")
# )

# You can zoom, click things, scroll, save image, etc. so you can actually see whats going on...but it keeps failing ("Error in dirname(to) : path too long")and I'm not in the mood to move things around, so back to normal ggplot...
TestQCPercentbyLocus %>%
  as_tibble(rownames = "locus") %>%
  gather(silly, percent,-locus) %>%
  ggplot(aes(x = silly, y = locus)) +
    geom_tile(aes(fill = percent), color = "white") +
    scale_fill_gradient(
      low = "black",
      high = "white",
      limits = c(0, 1)
    ) +
    ylab("Locus") +
    xlab("SILLY") +
    ggtitle("Percent genotyped by silly/locus") +
    labs(fill = "Percent\ngenotyped")
```

**0 / 298** loci failed; see table above. Some loci aren't too pretty, though.

## QA project genotypes

### Otoliths

#### Remove fails and dupes

Need to remove any particularly egregious project fish. *Here's where we can decide our cutoff, if any, for minimum number of loci.*

```{r}
PGOD21.gcl$counts[, , 1] %>% 
  as_tibble(rownames = "fish_id") %>% 
  gather(locus, genotype, -fish_id) %>% 
  group_by(fish_id) %>% 
  summarise(proportion_missing = sum(is.na(genotype)) / length(loci)) %>% 
  arrange(desc(proportion_missing))
```

There are 1,120 total otos in PGOD21 this first test round. If we went by the usual 80% rule on all 298 loci, we'd lose 692 otos, which is honestly not as bad as I thought it would be considering what we're dealing with. HOWEVER, we need to keep as many critters as possible. Plus, we're dealing with 298 loci, so we should have a lot of wiggle room considering the original panel was 96 (32% of loci) and we were considering paring that down to 24 (8% of loci). Granted, info content of each locus is not the same. 

So, for a first pass, let's try a 1% cutoff giving us a minimum of 3 loci that must be genotyped and losing 19 fish, leaving us with 1,101 fishies. We'll also largely skip the duplicate check (set at 99% matching), since it probably won't do us much good. We have (1) a low potential to identify true dupes, if there are few loci genotyped and (2) both lefts and unknowns in PGOD21, which could come from the same fish. NOTE: if this doesn't work well, as an alternate, we'll try a 10% cutoff giving us a minimum of 30 loci that must be genotyped and losing 85 fish, leaving us with 1,035 fishies. We'll still keep the duplicate rate check at 99%. 

```{r}
TestSillys_SampleSizes <-
  matrix(
    data = NA,
    nrow = length(TestSillys),
    ncol = 4,
    dimnames = list(TestSillys, c(
      "Genotyped", "Missing", "Duplicate", "Final"
    ))
  )

TestSillys_SampleSizes[, "Genotyped"] <-
  sapply(paste(TestSillys, ".gcl", sep = ''), function(x)
    get(x)$n)


(MissLoci <-
    RemoveIndMissLoci.GCL(sillyvec = TestSillys, proportion = 0.01))

ColSizePostMissLoci <-
  sapply(paste(TestSillys, ".gcl", sep = ''), function(x)
    get(x)$n)

TestSillys_SampleSizes[, "Missing"] <- TestSillys_SampleSizes[, "Genotyped"] - ColSizePostMissLoci

DuplicateCheck99MinProportion <-
  CheckDupWithinSilly.GCL(
    sillyvec = TestSillys,
    loci = loci,
    quantile = NULL,
    minproportion = 0.99
  )

DuplicateCheckReportSummary <-
  sapply(TestSillys, function(x)
    DuplicateCheck99MinProportion[[x]]$report, simplify = FALSE)

DuplicateCheckReportSummary

nDupsBySilly <-
  sapply(DuplicateCheckReportSummary, function(silly) {
    ifelse(is.character(silly), 0, nrow(as.matrix(silly)))
  })
RemovedDups <- RemoveDups.GCL(DuplicateCheck99MinProportion)

sapply(DuplicateCheckReportSummary[nDupsBySilly >= 1], function(silly) {
  if (1 %in% abs(as.numeric(levels(silly$ID1)) - as.numeric(levels(silly$ID2)))) {
    "Sequential IDs found as duplicates, check 'DuplicateCheckReportSummary' for duplicated rows"
  } else {
    "Duplicates exist, but IDs do not appear sequential"
  }
})

DuplicateCheckReportSummary[nDupsBySilly >= 1]  # Show within silly duplicates

ColSizePostDuplicate <- ColSizePostMissLoci - nDupsBySilly
ColSizePostDuplicate <- sapply(paste(TestSillys, ".gcl", sep = ''), function(x) get(x)$n)

TestSillys_SampleSizes[, "Duplicate"] <-
  ColSizePostMissLoci - ColSizePostDuplicate

TestSillys_SampleSizes[, "Final"] <- ColSizePostDuplicate

TestSillys_SampleSizes
```

**1 / 1101**  otos may be a duplicate. IDs aren't sequential (623 and 635), but they may have been in the same jumbled well together, so maybe we'll have to look a bit more closely at the specifics of these two.

#### Heterozygosity

Excess heterozygosity can be an indication of contamination. We already know there is some contamination among the heart-derived GT-seq genotypes, but it is a good baseline.

```{r}
Ho_qc <- function(indata1 = PGOD21.gcl$counts[ , , 1]) {
  indata1 %>% 
  as_tibble(rownames = "qc_fish_id") %>% 
  gather(locus, genotype, -qc_fish_id) %>% 
  group_by(qc_fish_id) %>% 
  summarise(Ho_qc = sum(genotype == 1, na.rm = TRUE) / length(!is.na(genotype)), .groups = "drop") %>% 
  arrange(desc(Ho_qc))
}

Ho_qc_plot <- function(indata2 = Ho_qc_PGOD21) {
  indata2 %>% 
  ggplot(aes(x = Ho_qc)) +
  geom_histogram(binwidth = 1/298) +
  theme_bw()
}

Ho_qc_PGOD21 <- Ho_qc()
Ho_qc_plot()
```

Ho is high for some otoliths, definitely due to contamination.

#### Genotyping success

Let's look at it again visually.

```{r}
# loci_intersect <- setdiff(loci, failed_loci_otoliths) # all 298 are there

qc_proportion_missing <- function(indata3 = PGOD21.gcl$counts[, , 1]) {
    indata3 %>%
    as_tibble(rownames = "fish_id") %>%
    gather(locus, genotype,-fish_id) %>%
    group_by(fish_id) %>%
    summarise(proportion_missing = sum(is.na(genotype)) / 298) %>%
    arrange(desc(proportion_missing))
}

qc_proportion_missing_plot <- function(indata4 = qc_proportion_missing_PGOD21) {
  indata4 %>% 
  ggplot(aes(x = proportion_missing)) +
  geom_histogram() +
  xlim(0, 1.1) +
  theme_bw()
}

qc_proportion_missing_PGOD21 <- qc_proportion_missing()
qc_proportion_missing_plot()
```

Yeah, it's not pretty - we know.

### Hearts

#### Remove fails and dupes

For the other SILLYS we'll compare to, we'll leave the cutoff at 80% and perform the regular 95% duplicate rate check.

```{r}
OGSillys <- c("PERB16", "PGILMOUR15", "PGILMOUR16", "PGILMOUR17", "PGILMOUR18", "PPADDY16")

OGSillys_SampleSizes <-
  matrix(
    data = NA,
    nrow = length(OGSillys),
    ncol = 4,
    dimnames = list(OGSillys, c(
      "Genotyped", "Missing", "Duplicate", "Final"
    ))
  )

OGSillys_SampleSizes[, "Genotyped"] <-
  sapply(paste(OGSillys, ".gcl", sep = ''), function(x)
    get(x)$n)


(MissLoci <-
    RemoveIndMissLoci.GCL(sillyvec = OGSillys, proportion = 0.8))

ColSizePostMissLoci <-
  sapply(paste(OGSillys, ".gcl", sep = ''), function(x)
    get(x)$n)

OGSillys_SampleSizes[, "Missing"] <- OGSillys_SampleSizes[, "Genotyped"] - ColSizePostMissLoci

DuplicateCheck95MinProportion <-
  CheckDupWithinSilly.GCL(
    sillyvec = OGSillys,
    loci = loci,
    quantile = NULL,
    minproportion = 0.95
  )

DuplicateCheckReportSummary <-
  sapply(OGSillys, function(x)
    DuplicateCheck95MinProportion[[x]]$report, simplify = FALSE)

DuplicateCheckReportSummary

nDupsBySilly <-
  sapply(DuplicateCheckReportSummary, function(silly) {
    ifelse(is.character(silly), 0, nrow(as.matrix(silly)))
  })
RemovedDups <- RemoveDups.GCL(DuplicateCheck95MinProportion)

sapply(DuplicateCheckReportSummary[nDupsBySilly >= 1], function(silly) {
  if (1 %in% abs(as.numeric(levels(silly$ID1)) - as.numeric(levels(silly$ID2)))) {
    "Sequential IDs found as duplicates, check 'DuplicateCheckReportSummary' for duplicated rows"
  } else {
    "Duplicates exist, but IDs do not appear sequential"
  }
})

DuplicateCheckReportSummary[nDupsBySilly >= 1]  # Show within silly duplicates

ColSizePostDuplicate <- ColSizePostMissLoci - nDupsBySilly
ColSizePostDuplicate <- sapply(paste(OGSillys, ".gcl", sep = ''), function(x) get(x)$n)

OGSillys_SampleSizes[, "Duplicate"] <-
  ColSizePostMissLoci - ColSizePostDuplicate

OGSillys_SampleSizes[, "Final"] <- ColSizePostDuplicate

OGSillys_SampleSizes
```

Losing a few more here as expected in terms of missingness. Only one dupe in PGILMOUR16. This is what we'd filter in a normal project anyway.

#### Heterozygosity

```{r}
Ho_qc_PERB16 <- Ho_qc(PERB16.gcl$counts[, , 1])
Ho_qc_PGILMOUR15 <- Ho_qc(PGILMOUR15.gcl$counts[, , 1])
Ho_qc_PGILMOUR16 <- Ho_qc(PGILMOUR16.gcl$counts[, , 1])
Ho_qc_PGILMOUR17 <- Ho_qc(PGILMOUR17.gcl$counts[, , 1])
Ho_qc_PGILMOUR18 <- Ho_qc(PGILMOUR18.gcl$counts[, , 1])
Ho_qc_PPADDY16 <- Ho_qc(PPADDY16.gcl$counts[, , 1])


Ho_qc_plot(Ho_qc_PERB16)
Ho_qc_plot(Ho_qc_PGILMOUR15)
Ho_qc_plot(Ho_qc_PGILMOUR16)
Ho_qc_plot(Ho_qc_PGILMOUR17)
Ho_qc_plot(Ho_qc_PGILMOUR18)
Ho_qc_plot(Ho_qc_PPADDY16)
```

Ho is higher for some hearts, likely due to contamination, but we already knew this, and compared to the PGOD21 otos, it's pretty low.

#### Genotyping success

```{r}
qc_proportion_missing_PERB16 <- qc_proportion_missing(PERB16.gcl$counts[, , 1])
qc_proportion_missing_PGILMOUR15 <- qc_proportion_missing(PGILMOUR15.gcl$counts[, , 1])
qc_proportion_missing_PGILMOUR16 <- qc_proportion_missing(PGILMOUR16.gcl$counts[, , 1])
qc_proportion_missing_PGILMOUR17 <- qc_proportion_missing(PGILMOUR17.gcl$counts[, , 1])
qc_proportion_missing_PGILMOUR18 <- qc_proportion_missing(PGILMOUR18.gcl$counts[, , 1])
qc_proportion_missing_PPADDY16 <- qc_proportion_missing(PPADDY16.gcl$counts[, , 1])

qc_proportion_missing_plot(qc_proportion_missing_PERB16)
qc_proportion_missing_plot(qc_proportion_missing_PGILMOUR15)
qc_proportion_missing_plot(qc_proportion_missing_PGILMOUR16)
qc_proportion_missing_plot(qc_proportion_missing_PGILMOUR17)
qc_proportion_missing_plot(qc_proportion_missing_PGILMOUR18)
qc_proportion_missing_plot(qc_proportion_missing_PPADDY16)
```

Lots less missing in the hearts.

### Final datasets

```{r}
PGOD21.gcl$n
PERB16.gcl$n
PGILMOUR15.gcl$n
PGILMOUR16.gcl$n
PGILMOUR17.gcl$n
PGILMOUR18.gcl$n
PPADDY16.gcl$n
```

We have a handful o' possible fishies to match back to. As a reminder, PGOD21 covered quite a few more SILLYs than we have heart genotypes for.

# #######################################

## Duplicate rate check

```{r}
# figure out the SILLYs associated with the DWPs and join
PGOD21_DWPs <- attributes_and_xfer_PGOD21 %>% 
  dplyr::select(`48_DWP_tray_barcode`) 
write_csv(PGOD21_DWPs, "PGOD21_DWPs.csv") # used this list and SILLY_CODE and DNA_TRAY_CODE in oceanak_affected_DWPs.csv to do a vlookup in excel for the SILLY_CODE associated with the 48_DWP_tray_barcode - I've since realized it's probably possible to do a vlookup type thing using join, but here we are...

PGOD21_DWPs_and_SILLYs <- read_csv("PGOD21_DWPs_and_SILLYs.csv") # renamed SILLY_CODE column in PGOD21_DWPs.csv to OG_SILLY_CODE, saved as new csv, and uploaded

attributes_xfer_and_SILLY_PGOD21 <- attributes_and_xfer_PGOD21 
attributes_xfer_and_SILLY_PGOD21$OG_SILLY_CODE <- PGOD21_DWPs_and_SILLYs$OG_SILLY_CODE

new_PGOD21_attributes_and_SILLY <- left_join(PGOD21.gcl$attributes, attributes_xfer_and_SILLY_PGOD21, by = "SillySource")

############### do I have to figure out how to reconstruct this *.gcl object first? Should I break everything down by DWP or SILLY?


```



```{r}
DupCheckResults <- DupCheckBetweenSillys.GCL(KeySillys = "PGOD21",
                            KeySillyIDs = list("PGOD21" = fish_ids),
                            BetweenSillys = OGSillys,
                            loci = loci,
                            threshold = 0.9)
```

Top pairwise duplicate rate comparisons

```{r}
(dup_check_results <- dplyr::bind_rows(DupCheckResults, .id = "silly") %>% 
   tibble::as_tibble())
```

How many PGOD21 fish match only 1 other fish?

```{r}
dup_check_results %>% 
  count(Keysillyvial) %>% 
  filter(n == 1) %>% 
  left_join(dup_check_results, by = "Keysillyvial")
```

How many PGOD21 fish match >1 other fish?

```{r}
dup_check_results %>% 
  count(Keysillyvial) %>% 
  filter(n > 1) %>% 
  left_join(dup_check_results, by = "Keysillyvial") %>% 
  arrange(Keysillyvial)
```

Check top match vs. 2nd best

```{r}
dup_check_all_top2 <- dup_check_all %>% 
  mutate(qc_fish_id = str_remove(string = qc_fish_id, pattern = "PGOD21"),
         fish_id = str_remove(string = fish_id, pattern = c("PGILMOUR15", "PGILMOUR16_", "PGILMOUR17_", "PGILMOUR18_", "PERB16_", "PERB18_", "PPADDY16_", "PPADDY18_"))) %>% 
  group_by(qc_fish_id) %>% 
  dplyr::top_n(duplicate_rate, n = 2) %>% 
  mutate(diff = max(duplicate_rate) - min(duplicate_rate)) %>% 
  top_n(duplicate_rate, n = 1) %>% 
  mutate(matchy = qc_fish_id == fish_id) %>% 
  ungroup()

dup_ties <- dup_check_all_top2 %>% 
  count(qc_fish_id) %>% 
  filter(n > 1) %>% 
  pull(qc_fish_id)

dup_check_all_top2 %>% 
  filter(!(qc_fish_id %in% dup_ties & matchy == TRUE)) %>% 
  select(qc_fish_id, matchy) %>% 
  distinct() %>% 
  count(matchy)

dup_check_all_top2 %>% 
  ggplot(aes(x = diff, y = duplicate_rate, colour = matchy, text = qc_fish_id)) +
  geom_point() +
  theme_bw()

plotly::ggplotly(ggplot(
  data = dup_check_all_top2,
  aes(
    x = diff,
    y = duplicate_rate,
    colour = best_match,
    text = qc_fish_id
  )
) +
  geom_point() +
  theme_bw())
```
